---
title: "Task 2"
author: "Max Settineri"
date: "2023-01-31"
output: html_document
---

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results = FALSE)

library(AICcmodavg)
library(tidyverse)
library(here)
library(equatiomatic)
library(kableExtra)
```

```{r}
calcofi <- read_csv(here('data', 'calcofi_seawater_samples.csv')) 
```

### Multiple Linear Regression Models

Creating two multiple linear regression models:

- Oxygen saturation as a function of water temperature, salinity, and phosphate concentration
- Oxygen saturation as a function of water temperature, salinity, phosphate concentration, and depth

```{r}
f1 <- o2sat ~ t_deg_c + salinity + po4u_m
model1 <- lm(f1, data = calcofi)

f2 <- o2sat ~ t_deg_c + salinity + po4u_m + depth_m
model2 <- lm(f2, data = calcofi)
```

### Using AIC to identify the better model

```{r}
aictab(list(model1, model2))
# AIC Model 1: 619.03
# AIC Model 2: 616.60

# making a table of AIC results
aictable <- aictab(list(model1, model2))
```

- **Model 1** has an AIC value of `r round(aictable$AICc[2], 2)`
- **Model 2** has an AIC value of `r round(aictable$AICc[1], 2)`
- The Delta AIC value of `r round(aictable$Delta_AICc[2], 2)` is large enough to indicate that model 2 is the best fit



### Using BIC to identify the better model

```{r}
bictab(list(model1, model2))
```

### Comparing models using ten-fold cross validation

```{r}
folds <- 10
fold_vec <- rep(1:folds, length.out = nrow(calcofi))

set.seed(42)
calcofi_fold <- calcofi %>% 
  mutate(group = sample(fold_vec, size = n(), replace = FALSE))

table(calcofi_fold$group)

test_df <- calcofi_fold %>% 
  filter(group ==1)
train_df <- calcofi_fold %>% 
  filter(group != 1)
```

```{r}
#creating a function for RMSE
calc_rmse <- function(x, y) {
  rmse <- (x - y)^2 %>% 
    mean() %>% 
    sqrt()
  return(rmse)
}
```

```{r}
# training the dataset for make two linear regression models

training_model1 <- lm(f1, data = train_df)
training_model2 <- lm(f2, data = train_df)

# predicting on test models using trained model

predict_test <- test_df %>% 
  mutate(model1 = predict(training_model1, test_df),
         model2 = predict(training_model2, test_df))

rmse_predict_test <- predict_test %>% 
  summarize(rmse_model1 = calc_rmse(model1, o2sat),
            rmse_model2 = calc_rmse(model2, o2sat))

kbl(rmse_predict_test, caption = "Table 2: Model 1 and Model 2 RMSE Value Outputs") %>% 
  kable_styling(c("striped"), full_width = FALSE)
```


```{r}
# iterating over all folds

rmse_df <- data.frame()

for(i in 1:folds) {
  kfold_test_df <- calcofi_fold %>% 
    filter(group == i)
  kfold_train_df <- calcofi_fold %>% 
    filter(group != i)
  
  kfold_model1 <- lm(f1, data = kfold_train_df)
  kfold_model2 <- lm(f2, data = kfold_train_df)
  
  kfold_pred_df <- kfold_test_df %>% 
    mutate(model1 = predict(kfold_model1, kfold_test_df),
           model2 = predict(kfold_model2, .))
  
  kfold_rmse_df <- kfold_pred_df %>% 
    summarize(rmse_model1 = calc_rmse(model1, o2sat),
              rmse_model2 = calc_rmse(model2, o2sat),
              test_gp = i)
  rmse_df <- bind_rows(rmse_df, kfold_rmse_df)
}

rmse_df %>% 
  summarize(mean_rmse_model1 = mean(rmse_model1),
            mean_rmse_model2 = mean(rmse_model2))
```

### Finalize the model

```{r}
final_model <- lm(f2, data = calcofi)
```

**Final model:**
`r extract_eq(final_model, wrap = TRUE)`

**Final model with coefficients:**
`r extract_eq(final_model, wrap = TRUE, use_coefs = TRUE)`


**Data Citation:** CalCOFI data are available for use without restriction. Data downloaded from https://calcofi.org/ccdata.html.  Accessed 1/31/2023.
